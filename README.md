# Attention Plasticity Toolkit

Utilities for measuring how much individual transformer attention heads rely on position and how flexibly they can change key preferences (“attention plasticity”). Feed it q/k dumps from [qk-sniffer](https://github.com/cgansen/qk-sniffer) (or any dataset matching the same schema) and it emits per-head CSV metrics plus visualizations.

## Highlights
- **Head-by-head analytics** – quantify positional predictability, residual normality, and overall attention plasticity for every `(layer, query head, key head)` triple.
- **Bucket-aware modeling** – automatically handles sliding-window dumps and only compares keys from earlier buckets when estimating plasticity.
- **Config-driven runs** – point the CLI at a YAML file to switch models, datasets, sampling budgets, worker count, and output destinations.
- **Publication-ready plots** – turn CSV outputs into layered trend plots with per-head traces and mean curves.

## Repository Map
```
attention_plasticity/    Core analysis + helpers (config, stats, plasticity, data utils)
analyze.py               CLI entry point for running the per-head analysis
scripts/plot_plasticity.py CLI tool to plot per-bucket plasticity curves
configs/                 Example run + plotting configs
results/                 Sample outputs (SmolLM2-135M)
tests/                   Pytest suite for the core functionality
```

## Requirements
- Python 3.10+
- A q/k dataset per attention head (typically generated by [qk-sniffer](https://github.com/viktor-shcherb/qk-sniffer)) published to Hugging Face Datasets or stored locally.
- System libs needed by `datasets`, `numpy`, `pandas`, `scipy`, and `matplotlib`.

Install dependencies in a fresh environment:
```bash
python -m venv .venv
source .venv/bin/activate
pip install -e .
```

## Preparing Data
Each head needs two dataset configs: `lXXhYYq` (queries) and `lXXhZZk` (keys) stored under a base directory. Example (`configs/smollm2-135m.yaml`):
```
model_dir: HuggingFaceTB_SmolLM2_135M
num_layers: 30
num_q_heads: 9
num_k_heads: 3
```
The script infers key-head indices by grouping query heads evenly across key heads (supports GQA layouts). Datasets must expose a `train` split whose rows include
- `bucket` (int): geometric or uniform bucket id
- `position` (float): effective position in tokens
- `vector` (float list): embedding for that token
- Optional `sliding_window` column (int or null) indicating rolling-context window size; when set, attention plasticity sampling respects that window automatically (always including at least the immediately-previous bucket)

## Running the Analysis
1. Edit or copy `configs/smollm2-135m.yaml` to match your model, dataset name, bucket counts, and output paths.
2. Launch the CLI:
   ```bash
   python analyze.py --config configs/smollm2-135m.yaml
   ```
   Any flag can override the YAML at runtime (e.g., `--max_workers 4`, `--dataset_name your-user/sniffed-qk`).
3. The CLI first downloads (or reuses) a local snapshot of the dataset via `huggingface_hub.snapshot_download`. Set `dataset_local_root` if you already have the files on disk, or `dataset_cache_dir`/`download_max_workers` to control where/how the snapshot is stored. Once cached, the script processes every query head, writing
   - `head_metrics.csv`: per-head summary stats (positions R², MAE ratios, residual skew/kurtosis, KS pass rates, `ap_overall`).
   - `head_bucket_plasticity.csv`: plasticity per `(q_bucket, k_bucket)` per head (skips `q_bucket=0`, may contain NaNs when a bucket lacks query or key pairs).
   - `head_component_weights.csv`: per-component positional R² plus normalized “share of linear positional information” weights (each head sums to 1 across components).

Progress messages note which head has completed and highlight errors (e.g., shape mismatches, missing datasets).

## Plotting Plasticity
Turn the bucket CSV into a figure showing every head plus the mean curve:
```bash
python scripts/plot_plasticity.py --config configs/plots/smollm2-135m-plasticity.yaml
```
Key options (CLI flags or YAML):
- `bucket_csv`: path to `head_bucket_plasticity.csv`
- `bucket_type`: `uniform` (default) or `log` for geometric spacing
- `bucket_min_size`: bucket width (or multiplier for log scale)
- `model_name`: label added to the title
- `color_by_layer` or `color_trend`: highlight traces by layer index or monotonic trend
- `output`: save to a file instead of showing interactively

For a model-level view of how queries attend to earlier buckets, render a 2D
histogram (q_bucket vs. k_bucket) with attention plasticity as the cell color:
```bash
python scripts/plot_bucket_heatmap.py --bucket_csv results/qwen3-8b/head_bucket_plasticity.csv --output bucket_heatmap.png
```
Use `--agg median` to aggregate with a median instead of mean, and tweak `--cmap`,
`--vmin`, `--vmax`, or `--title` for presentation tweaks. Positions on both axes
are taken from the *start* of each bucket (`bucket_type`=`uniform` uses
`bucket * bucket_min_size`, `log` uses `2^bucket * bucket_min_size`). The script
also accepts YAML configs
(e.g., `--config configs/plots/qwen3-8b-heatmap.yaml` or
`configs/plots/smollm2-135m-heatmap.yaml`) mirroring the CLI flags.

To see where the model stores positional information in the rotated embedding
space, average the per-component weights and draw a bar chart:
```bash
python scripts/plot_component_weights.py --config configs/plots/qwen3-8b-components.yaml
```
This script expects `head_component_weights.csv` and normalizes every head so its
component weights sum to 1 before averaging, making it easy to highlight common
components that carry positional “linear information.”

## Configuration Reference
Every run starts from a YAML file with at least these fields:
| Field | Description |
| --- | --- |
| `model_dir` | Base directory containing `lXXhYY{q,k}` dataset shards |
| `dataset_name` | Hugging Face dataset identifier (defaults to `viktoroo/sniffed-qk`) |
| `num_layers` | Transformer layers to scan |
| `num_q_heads` / `num_k_heads` | Query and key heads per layer; query heads must be a multiple of key heads |
| `dataset_local_root` | Optional path to an already-downloaded dataset snapshot (skips downloading) |
| `dataset_cache_dir` | Custom cache directory to store the snapshot (defaults to Hugging Face cache) |
| `download_max_workers` | Max workers for `snapshot_download` (defaults to library value) |
| `max_tokens_per_head` | Cap on tokens sampled per head (random without replacement) |
| `normality_max_dims` | Max number of noise dims tested for KS statistics |
| `p_alpha` | Significance level for KS tests |
| `seed` | RNG seed controlling subsampling and bucket pair sampling |
| `output_csv`, `bucket_csv`, `component_csv` | Paths for per-head metrics, per-bucket plasticities, and per-component weights |
| `max_workers` | Process pool size (`None` = CPU count)

## Testing
Run the built-in tests to ensure dependencies and helpers are wired correctly:
```bash
pytest
```
Tests create dummy datasets to validate regressors, orientation logic, sliding-window handling, and config loading.

## Troubleshooting
- **Missing datasets**: confirm the Hugging Face dataset repo exists and contains the `data_dir` subfolders referenced via `model_dir`.
- **Shape mismatches**: verify query/key dumps use the same embedding width.
- **NaN plasticities**: occur when a bucket lacks either queries or at least two eligible keys; increase token caps or widen sliding windows.
- **Slow runs**: reduce `max_tokens_per_head` or `num_pairs_per_bucket` (edit `attention_plasticity/plasticity.py`), or set `--max_workers` to leverage more cores.

## Citation
If you use this toolkit in a paper or blog post, please credit “Attention Plasticity Toolkit (2025)” and link to this repository. Contributions, bug reports, and feature requests are welcome!
